{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2s023VS6NvV5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import spotipy\n",
        "import sqlite3\n",
        "from sklearn.cluster import KMeans\n",
        "from sqlite3 import Error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from spotipy.oauth2 import SpotifyOAuth\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from openTSNE import TSNE as openTSNE\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS as STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWnx-v7ONvWA"
      },
      "outputs": [],
      "source": [
        "def connect_db(db_file):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "    except Error as e:\n",
        "        print(e)\n",
        "    return conn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IwvA8npiNvWB"
      },
      "outputs": [],
      "source": [
        "# connect to database\n",
        "conn = connect_db('data.db')\n",
        "cur = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting the target data\n",
        "# Extract playlists that have the input words in their titles to use as training data\n",
        "input_words = ['summer', 'beach', 'throwbacks']\n",
        "# sql_select = '''SELECT AVG(danceability), AVG(energy), AVG(key), AVG(loudness), \n",
        "# AVG(mode), AVG(speechiness), AVG(acousticness), AVG(instrumentalness), AVG(liveness), \n",
        "# AVG(valence), AVG(tempo), AVG(duration_ms), AVG(time_signature) FROM avg_features_by_playlist WHERE'''\n",
        "\n",
        "sql_select = '''SELECT * FROM avg_features_by_playlist WHERE'''\n",
        "for w in range(len(input_words)):\n",
        "    sql_select += \" name LIKE '%\" + input_words[w] + \"%'\"\n",
        "    if w != len(input_words) -1:\n",
        "        sql_select += \" OR\" \n",
        "pl_train = cur.execute(sql_select).fetchall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PCfDJLzmNvWB",
        "outputId": "994a0280-a025-4982-83fd-bfe5a120c0c3"
      },
      "outputs": [],
      "source": [
        "# Get X data (average playlist features)\n",
        "data_cols = ['pid', 'name', 'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "feature_cols = ['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "test_cols = ['pid', 'name', 'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "\n",
        "data_rows = cur.execute('select * from avg_features_by_playlist where pid > (select MIN(pid) from avg_features_by_playlist) order by pid').fetchall()\n",
        "\n",
        "\n",
        "# test_pl = cur.execute('''select tracks_in_playlist.pid, tracks_in_playlist.track_uri, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_ms, time_signature \n",
        "# from features_by_track left join tracks_in_playlist on\n",
        "# features_by_track.track_uri = tracks_in_playlist.track_uri \n",
        "# where pid = (select MIN(pid) from avg_features_by_playlist)''').fetchall()\n",
        "\n",
        "\n",
        "test_data = pd.DataFrame(pl_train, columns=test_cols)\n",
        "data = pd.DataFrame(data_rows, columns=data_cols)\n",
        "\n",
        "print(test_data.head())\n",
        "print(data.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ghXip9j4NvWD",
        "outputId": "b190b543-e694-46f0-a331-07272e7562a0"
      },
      "outputs": [],
      "source": [
        "# Scale the data\n",
        "\n",
        "\n",
        "y = test_data[feature_cols].mean()\n",
        "\n",
        "scaler = StandardScaler(with_mean=True, with_std=True).fit(data[feature_cols].values)\n",
        "\n",
        "scaled_x = scaler.transform(data[feature_cols].values)\n",
        "scaled_y = scaler.transform(np.array(y).reshape(1,-1))\n",
        "scaled_features = pd.DataFrame(scaled_x)\n",
        "tsne = openTSNE(perplexity=30, metric='euclidean', n_jobs=-1, random_state=0, verbose=False)\n",
        "tsne_transformer = tsne.fit(scaled_x)\n",
        "data_df = pd.DataFrame(tsne_transformer.transform(scaled_x), columns =['X', 'Y'])\n",
        "\n",
        "print(data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qf9YiqzqNvWE",
        "outputId": "7cac83b7-e7e3-4125-a6ce-0f8ee47f6d64"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='X', y='Y', data=data_df, legend=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MxtQj6Khbe4e"
      },
      "outputs": [],
      "source": [
        "#TODO:\n",
        "# needs to be tested and K updated below\n",
        "#calculate how many K clusters there should be \n",
        "wcss = [] \n",
        "for number_of_clusters in range(1, 30): \n",
        "    kmeans = KMeans(n_clusters = number_of_clusters, random_state = 42)\n",
        "    kmeans.fit(scaled_x) \n",
        "    wcss.append(kmeans.inertia_)\n",
        "wcss\n",
        "\n",
        "ks = range(1, 30)\n",
        "plt.plot(ks, wcss)\n",
        "plt.axvline(4, linestyle='--', color='r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HboT_UKqNvWF"
      },
      "outputs": [],
      "source": [
        "# initialize KMeans\n",
        "n_clusters = 20\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "clusters = kmeans.fit(scaled_x)\n",
        "labels = clusters.labels_\n",
        "data_df['cluster'] = pd.Categorical(labels)\n",
        "\n",
        "target_cluster = kmeans.predict(scaled_y)\n",
        "print(target_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czsdHYnjNvWG",
        "outputId": "437142d0-73d2-4d1b-925b-0643ca9bddaa"
      },
      "outputs": [],
      "source": [
        "sns.scatterplot(x='X', y='Y', hue='cluster', style='cluster', data=data_df, legend=None)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "data_df[\"playlist_name\"] = data['name'].str.lower()\n",
        "# display(data_df)\n",
        "\n",
        "# we want to perform a pivot on data_df so that each cluster number is a column with row value equal to the playlist name.\n",
        "# from there we can sum up that column to get the whole lsit of strings of playlist names for each cluster (column)\n",
        "original_df = data_df.pivot(index='X', columns='cluster')['playlist_name'].reset_index()\n",
        "original_df.columns.name = None\n",
        "original_df = original_df.fillna('')\n",
        "# original_df.head(20)\n",
        "# print(original_df.columns)\n",
        "\n",
        "#list of words to ignore\n",
        "stop_words = STOPWORDS.update([\"i\", \"it\", \"me\", \"my\", \"that\", \"the\", \"of\", \"than\", \"then\", \n",
        "\"when\", \"if\", \"a\", \"there\", \"playlist\", \"music\", \"song\", \"songs\", \"to\", \"too\", \"get\", \"as\", \"this\", \n",
        "\"am\", \"is\", \"are\", \"has\", \"and\", \"aa\", \"aaa\", 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', \n",
        "'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
        "\n",
        "wordclouds = {}\n",
        "for i in range(n_clusters):\n",
        "    original_df.replace(np.nan, '')\n",
        "    original_df[i] = original_df[i].astype(str) #.sum(skipna=True))\n",
        "    wordclouds[\"wordcloud\" + str(i)] = WordCloud(stopwords=stop_words).generate(' '.join(original_df[i]))\n",
        "\n",
        "for val in wordclouds.values():\n",
        "    plt.imshow(val)\n",
        "    plt.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_target_cluster_songs(target_cluster):\n",
        "    data_df[\"pid\"] = data['pid']\n",
        "    original_df = data_df.pivot(columns='cluster', values='pid')\n",
        "    target_cluster_df = original_df[[target_cluster]].dropna()\n",
        "    conn = connect_db('data.db')\n",
        "    cur = conn.cursor()\n",
        "    sql = '''SELECT features_by_track.* FROM features_by_track join tracks_in_playlist on features_by_track.track_uri = tracks_in_playlist.track_uri\n",
        "        WHERE '''\n",
        "    for pid in target_cluster_df[target_cluster].values:\n",
        "        sql += \"tracks_in_playlist.pid = \" + str(int(pid))\n",
        "        sql += \" OR \"\n",
        "    sql = sql[:-3]\n",
        "    cols = [\"track_uri\",\n",
        "        \"danceability\",\n",
        "        \"energy\",\n",
        "        \"key\",\n",
        "        \"loudness\",\n",
        "        \"mode\",\n",
        "        \"speechiness\",\n",
        "        \"acousticness\",\n",
        "        \"instrumentalness\",\n",
        "        \"liveness\",\n",
        "        \"valence\",\n",
        "        \"tempo\",\n",
        "        \"duration_ms\",\n",
        "        \"time_signature\"]\n",
        "        \n",
        "    result = cur.execute(sql).fetchall()\n",
        "    \n",
        "    conn.close()\n",
        "    tracks = pd.DataFrame(result, columns = cols)\n",
        "    tracks = tracks[tracks['track_uri'].map(tracks['track_uri'].value_counts()) > 3]\n",
        "    \n",
        "    tracks['counts'] = tracks.groupby(['track_uri'])['time_signature'].transform('count')\n",
        "    \n",
        "    tracks = tracks.drop_duplicates(subset=['track_uri'])\n",
        "    song_instances = tracks['counts'].sum()\n",
        "\n",
        "    \n",
        "    #num_unique_songs = len(pd.unique(tracks['track_uri']))\n",
        "    print(song_instances, \" song instances fetched\")\n",
        "    print(len(tracks), \" unique songs fetched\")\n",
        "    print(tracks.head(5))\n",
        "    return tracks\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_cluster_songs = get_target_cluster_songs(target_cluster[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "target_cluster_songs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "feature_cols.append('counts')\n",
        "scaler_song = StandardScaler(with_mean=True, with_std=True).fit(target_cluster_songs[feature_cols].values)\n",
        "\n",
        "scaled_song_x = scaler_song.transform(target_cluster_songs[feature_cols].values)\n",
        "scaled_song_features = pd.DataFrame(scaled_song_x)\n",
        "tsne_song = openTSNE(perplexity=30, metric='euclidean', n_jobs=-1, random_state=0, verbose=False)\n",
        "tsne_transformer_song = tsne_song.fit(scaled_song_x)\n",
        "song_data_df = pd.DataFrame(tsne_transformer_song.transform(scaled_song_x), columns =['X', 'Y'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_song_target_cluster_songs(target_cluster):\n",
        "    song_data_df[\"track_uri\"] = target_cluster_songs['track_uri']\n",
        "    original_df = song_data_df.pivot(columns='cluster', values='track_uri')\n",
        "    target_cluster_df = original_df[[target_cluster]].dropna()\n",
        "    \n",
        "    conn = connect_db('data.db')\n",
        "    cur = conn.cursor()\n",
        "    sql = \"SELECT track_name, track_uri FROM tracks WHERE \"\n",
        "    for uri in target_cluster_df[target_cluster].values:\n",
        "        sql += \"track_uri = \" + \"\\\"\" + uri + \"\\\"\"\n",
        "        sql += \" OR \"\n",
        "    sql = sql[:-3]\n",
        "    cols = [\"track_name\", \"track_uri\"]\n",
        "    \n",
        "    result = cur.execute(sql).fetchall()\n",
        "    conn.close()\n",
        "\n",
        "    tracks = pd.DataFrame(result, columns = cols)\n",
        "\n",
        "    unique_songs = pd.unique(tracks['track_uri'])\n",
        "    print(len(unique_songs), \" songs fetched\")\n",
        "    print(unique_songs)\n",
        "    return unique_songs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def connect_to_spotify():\n",
        "    # Spotify credentials\n",
        "    cid = \"5cffc2676cd44b35bc6af81faeb8e69a\"\n",
        "    secret = \"f9fdae88362349b992ab2714ea91a094\"\n",
        "    os.environ[\"SPOTIPY_CLIENT_ID\"] = cid\n",
        "    os.environ[\"SPOTIPY_CLIENT_SECRET\"] = secret\n",
        "    os.environ['SPOTIPY_REDIRECT_URI'] = \"http://127.0.0.1:8080\"\n",
        "    client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
        "    sp = spotipy.Spotify(client_credentials_manager = SpotifyClientCredentials())\n",
        "\n",
        "    return sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sp = connect_to_spotify()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "\n",
        "def generate_playlist(song_df, center_x, center_y, ids):\n",
        "    \n",
        "    # drop URI, for whatever reason it's empty and useless for this\n",
        "    song_df = song_df.drop(columns='track_uri')\n",
        "    \n",
        "    # x2 - x1\n",
        "    x_vals = song_df['X'].apply(lambda x: x - center_x)\n",
        "    \n",
        "    # y2 - y1\n",
        "    y_vals = song_df['Y'].apply(lambda x: x - center_y)\n",
        "    \n",
        "    # square both\n",
        "    x_vals = np.power(x_vals, 2)\n",
        "    y_vals = np.power(y_vals, 2)\n",
        "\n",
        "    # final distances between the center and all of the points\n",
        "    distances = np.sqrt(x_vals + y_vals)\n",
        "    \n",
        "    \n",
        "    # now append the song ids column!\n",
        "    distances =  pd.DataFrame(distances)\n",
        "    distances['id'] = ids\n",
        "    \n",
        "    # sort by distance and return the whole thing\n",
        "    sorted_distances = distances.sort_values(by=0)\n",
        "    closest_song_ids = sorted_distances\n",
        "    return closest_song_ids\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import spotipy.util as util\n",
        "\n",
        "#must give a list of track ids, must include \"spotify:track:\"\n",
        "user_id = \"1a0f1b9085db4f49\"\n",
        "username = \"31y7j5k3jeidd5rzhaznsdregg34\"\n",
        "playlistName = \"\"\n",
        "scope = \"playlist-modify-public\"\n",
        "songs_to_add = []\n",
        "c = 0\n",
        "for i in input_words:\n",
        "    playlistName += input_words[c] + \" \"\n",
        "    c += 1\n",
        "    \n",
        "results = target_cluster_songs['track_uri']\n",
        "results = results.values.tolist()\n",
        "\n",
        "\n",
        "centers = clusters.cluster_centers_[target_cluster]\n",
        "\n",
        "\n",
        "results = generate_playlist(song_data_df, centers[:, 0][0], centers[:, 1][0], results)['id'].tolist()\n",
        "\n",
        "c = 0\n",
        "for track in range(99):\n",
        "    songs_to_add.append(\"spotify:track:\" + results[c])\n",
        "    c += 1\n",
        "\n",
        "token = SpotifyOAuth(scope = scope, username = username)\n",
        "if token:\n",
        "    sp = spotipy.Spotify(auth_manager=token)\n",
        "    sp.user_playlist_create(user = username, name = playlistName)\n",
        "    prep = sp.user_playlists(user = username)\n",
        "    playlist = prep['items'][0]['id']\n",
        "    sp.user_playlist_add_tracks(user = username, playlist_id= playlist, tracks=songs_to_add)\n",
        "else:\n",
        "    print(\"Can't get token for\", username)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e8398f7b216cace33c4ab6b86eb2f74027b6a3057174f31fee5a9109c187293f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
