{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2s023VS6NvV5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import spotipy\n",
        "import sqlite3\n",
        "from sklearn.cluster import KMeans\n",
        "from sqlite3 import Error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import time\n",
        "import gradio as gr\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from openTSNE import TSNE as openTSNE\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS as STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GWnx-v7ONvWA"
      },
      "outputs": [],
      "source": [
        "def connect_db(db_file):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "    except Error as e:\n",
        "        print(e)\n",
        "    return conn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "IwvA8npiNvWB"
      },
      "outputs": [],
      "source": [
        "# connect to database\n",
        "# conn = connect_db('data.db')\n",
        "# cur = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting the target data\n",
        "# Extract playlists that have the input words in their titles to use as training data\n",
        "# input_words = ['summer', 'beach', 'throwbacks']\n",
        "# sql_select = '''SELECT AVG(danceability), AVG(energy), AVG(key), AVG(loudness), \n",
        "# AVG(mode), AVG(speechiness), AVG(acousticness), AVG(instrumentalness), AVG(liveness), \n",
        "# AVG(valence), AVG(tempo), AVG(duration_ms), AVG(time_signature) FROM avg_features_by_playlist WHERE'''\n",
        "def create_train(input_words, cur):\n",
        "    sql_select = '''SELECT * FROM avg_features_by_playlist WHERE'''\n",
        "    for w in range(len(input_words)):\n",
        "        sql_select += \" name LIKE '%\" + input_words[w] + \"%'\"\n",
        "        if w != len(input_words) -1:\n",
        "            sql_select += \" OR\" \n",
        "    pl_train = cur.execute(sql_select).fetchall()\n",
        "    return pl_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PCfDJLzmNvWB",
        "outputId": "994a0280-a025-4982-83fd-bfe5a120c0c3"
      },
      "outputs": [],
      "source": [
        "def get_x_data(pl_train, cur):\n",
        "    # Get X data (average playlist features)\n",
        "    data_cols = ['pid', 'name', 'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "    feature_cols = ['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "    test_cols = ['pid', 'name', 'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "\n",
        "    data_rows = cur.execute('select * from avg_features_by_playlist where pid > (select MIN(pid) from avg_features_by_playlist) order by pid').fetchall()\n",
        "\n",
        "\n",
        "    # test_pl = cur.execute('''select tracks_in_playlist.pid, tracks_in_playlist.track_uri, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_ms, time_signature \n",
        "    # from features_by_track left join tracks_in_playlist on\n",
        "    # features_by_track.track_uri = tracks_in_playlist.track_uri \n",
        "    # where pid = (select MIN(pid) from avg_features_by_playlist)''').fetchall()\n",
        "\n",
        "\n",
        "    test_data = pd.DataFrame(pl_train, columns=test_cols)\n",
        "    data = pd.DataFrame(data_rows, columns=data_cols)\n",
        "\n",
        "    return test_data, test_cols, data, data_cols, feature_cols\n",
        "    # print(test_data.head())\n",
        "    # print(data.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ghXip9j4NvWD",
        "outputId": "b190b543-e694-46f0-a331-07272e7562a0"
      },
      "outputs": [],
      "source": [
        "# Scale the data\n",
        "\n",
        "def scale_data(test_data, data, feature_cols):\n",
        "    y = test_data[feature_cols].mean()\n",
        "\n",
        "    scaler = StandardScaler(with_mean=True, with_std=True).fit(data[feature_cols].values)\n",
        "\n",
        "    scaled_x = scaler.transform(data[feature_cols].values)\n",
        "    scaled_y = scaler.transform(np.array(y).reshape(1,-1))\n",
        "    scaled_features = pd.DataFrame(scaled_x)\n",
        "    tsne = openTSNE(perplexity=30, metric='euclidean', n_jobs=-1, random_state=0, verbose=False)\n",
        "    tsne_transformer = tsne.fit(scaled_x)\n",
        "    data_df = pd.DataFrame(tsne_transformer.transform(scaled_x), columns =['X', 'Y'])\n",
        "\n",
        "    #print(data_df, scaled_x, scaled_y, scaled_features)\n",
        "    return data_df, scaled_x, scaled_y, scaled_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "qf9YiqzqNvWE",
        "outputId": "7cac83b7-e7e3-4125-a6ce-0f8ee47f6d64"
      },
      "outputs": [],
      "source": [
        "def draw_scatterplot(data_df):\n",
        "    sns.scatterplot(x='X', y='Y', data=data_df, legend=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MxtQj6Khbe4e"
      },
      "outputs": [],
      "source": [
        "def calculate_num_clusters(scaled_x):\n",
        "    #TODO:\n",
        "    # needs to be tested and K updated below\n",
        "    #calculate how many K clusters there should be \n",
        "    wcss = [] \n",
        "    for number_of_clusters in range(1, 30): \n",
        "        kmeans = KMeans(n_clusters = number_of_clusters, random_state = 42)\n",
        "        kmeans.fit(scaled_x) \n",
        "        wcss.append(kmeans.inertia_)\n",
        "    wcss\n",
        "\n",
        "    ks = range(1, 30)\n",
        "    plt.plot(ks, wcss)\n",
        "    plt.axvline(4, linestyle='--', color='r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "HboT_UKqNvWF"
      },
      "outputs": [],
      "source": [
        "def kmeans_init(data_df, scaled_x, scaled_y, n_clusters):\n",
        "    # initialize KMeans\n",
        "    \n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "    clusters = kmeans.fit(scaled_x)\n",
        "    labels = clusters.labels_\n",
        "    data_df['cluster'] = pd.Categorical(labels)\n",
        "    \n",
        "    target_cluster = kmeans.predict(scaled_y)\n",
        "    return (target_cluster, labels, data_df['cluster'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "czsdHYnjNvWG",
        "outputId": "437142d0-73d2-4d1b-925b-0643ca9bddaa"
      },
      "outputs": [],
      "source": [
        "def draw_colored_scatterplot(data_df):\n",
        "    sns.scatterplot(x='X', y='Y', hue='cluster', style='cluster', data=data_df, legend=None)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wordclouds(data_df, data, n_clusters):\n",
        "    data_df[\"playlist_name\"] = data['name'].str.lower()\n",
        "    # display(data_df)\n",
        "\n",
        "    # we want to perform a pivot on data_df so that each cluster number is a column with row value equal to the playlist name.\n",
        "    # from there we can sum up that column to get the whole lsit of strings of playlist names for each cluster (column)\n",
        "    original_df = data_df.pivot(index='X', columns='cluster')['playlist_name'].reset_index()\n",
        "    original_df.columns.name = None\n",
        "    original_df = original_df.fillna('')\n",
        "    # original_df.head(20)\n",
        "    # print(original_df.columns)\n",
        "\n",
        "    #list of words to ignore\n",
        "    stop_words = STOPWORDS.update([\"i\", \"it\", \"me\", \"my\", \"that\", \"the\", \"of\", \"than\", \"then\", \n",
        "    \"when\", \"if\", \"a\", \"there\", \"playlist\", \"music\", \"song\", \"songs\", \"to\", \"too\", \"get\", \"as\", \"this\", \n",
        "    \"am\", \"is\", \"are\", \"has\", \"and\", \"aa\", \"aaa\", 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', \n",
        "    'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
        "\n",
        "    wordclouds = {}\n",
        "    for i in range(n_clusters):\n",
        "        original_df.replace(np.nan, '')\n",
        "        original_df[i] = original_df[i].astype(str) #.sum(skipna=True))\n",
        "        wordclouds[\"wordcloud\" + str(i)] = WordCloud(stopwords=stop_words).generate(' '.join(original_df[i]))\n",
        "\n",
        "    # for val in wordclouds.values():\n",
        "    #     plt.imshow(val)\n",
        "    #     plt.axis(\"off\")\n",
        "    #     plt.show()\n",
        "    return wordclouds.values()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_target_cluster_songs(target_cluster, data_df, data):\n",
        "    data_df[\"pid\"] = data['pid']\n",
        "    original_df = data_df.pivot(columns='cluster', values='pid')\n",
        "    target_cluster_df = original_df[[target_cluster]].dropna()\n",
        "    conn = connect_db('data.db')\n",
        "    cur = conn.cursor()\n",
        "    \n",
        "    print(target_cluster_df)\n",
        "    exit()\n",
        "    num_of_ors = 0\n",
        "    \n",
        "    sql = '''SELECT features_by_track.* FROM features_by_track join tracks_in_playlist on features_by_track.track_uri = tracks_in_playlist.track_uri\n",
        "        WHERE '''\n",
        "    \n",
        "    result = []\n",
        "    \n",
        "    for pid in target_cluster_df[target_cluster].values:\n",
        "        sql += \"tracks_in_playlist.pid = \" + str(int(pid))\n",
        "        sql += \" OR \"\n",
        "        num_of_ors += 1\n",
        "        if (num_of_ors == 100):\n",
        "            sql = sql[:-3]\n",
        "            cols = [\"track_uri\",\n",
        "                \"danceability\",\n",
        "                \"energy\",\n",
        "                \"key\",\n",
        "                \"loudness\",\n",
        "                \"mode\",\n",
        "                \"speechiness\",\n",
        "                \"acousticness\",\n",
        "                \"instrumentalness\",\n",
        "                \"liveness\",\n",
        "                \"valence\",\n",
        "                \"tempo\",\n",
        "                \"duration_ms\",\n",
        "                \"time_signature\"]\n",
        "            result.append(cur.execute(sql).fetchall())\n",
        "            sql = '''SELECT features_by_track.* FROM features_by_track join tracks_in_playlist on features_by_track.track_uri = tracks_in_playlist.track_uri\n",
        "            WHERE '''\n",
        "            num_of_ors = 0\n",
        "        \n",
        "    conn.close()\n",
        "    tracks = pd.DataFrame(result, columns = cols)\n",
        "    tracks = tracks[tracks['track_uri'].map(tracks['track_uri'].value_counts()) > 3]\n",
        "    \n",
        "    tracks['counts'] = tracks.groupby(['track_uri'])['time_signature'].transform('count')\n",
        "    \n",
        "    tracks = tracks.drop_duplicates(subset=['track_uri'])\n",
        "    song_instances = tracks['counts'].sum()\n",
        "\n",
        "    \n",
        "    #num_unique_songs = len(pd.unique(tracks['track_uri']))\n",
        "    print(song_instances, \" song instances fetched\")\n",
        "    print(len(tracks), \" unique songs fetched\")\n",
        "    print(tracks.head(5))\n",
        "    return tracks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "generate_playlist\n",
        "\n",
        "Parameters:\n",
        "input_words: (String) to pass to get_target_cluster_songs\n",
        "obscurity: (float) int\n",
        "max_song_length: (int) max_length of any song in the playlist\n",
        "use_minutes: (bool) use minutes instead of number of songs for playlist length (default false)\n",
        "playlist_length: number of songs in the playlist. If use_minutes=true, minutes in the playlist\n",
        "'''\n",
        "\n",
        "def generate_playlist(tracks, obscurity=1, max_song_length=10, use_minutes=False, playlist_length=10):\n",
        "    playlist = []\n",
        "    \n",
        "    \n",
        "    # obscurity\n",
        "    # length\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def connect_to_spotify():\n",
        "    # Spotify credentials\n",
        "    cid = \"5cffc2676cd44b35bc6af81faeb8e69a\"\n",
        "    secret = \"f9fdae88362349b992ab2714ea91a094\"\n",
        "    os.environ[\"SPOTIPY_CLIENT_ID\"] = cid\n",
        "    os.environ[\"SPOTIPY_CLIENT_SECRET\"] = secret\n",
        "    os.environ['SPOTIPY_REDIRECT_URI'] = \"http://127.0.0.1:8080\"\n",
        "    client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
        "    sp = spotipy.Spotify(client_credentials_manager = SpotifyClientCredentials())\n",
        "\n",
        "    return sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_playlist(sp, songs, input_words):\n",
        "    #must give a list of track ids, must include \"spotify:track:\"\n",
        "    user_id = \"1a0f1b9085db4f49\"\n",
        "    username = \"31y7j5k3jeidd5rzhaznsdregg34\"\n",
        "    playlistName = \"\"\n",
        "    scope = \"playlist-modify-public\"\n",
        "    songs_to_add = []\n",
        "    c = 0\n",
        "    for i in input_words:\n",
        "        playlistName += input_words[c] + \" \"\n",
        "        c += 1\n",
        "        \n",
        "    c = 0\n",
        "    for i in songs_to_add:\n",
        "        songs_to_add[c] = \"spotify:track:\" + songs['track_uri']\n",
        "        c += 1\n",
        "\n",
        "    token = SpotifyOAuth(scope = scope, username = username)\n",
        "    if token:\n",
        "        sp = spotipy.Spotify(auth_manager=token)\n",
        "        sp.user_playlist_create(user = username, name = playlistName)\n",
        "        prep = sp.user_playlists(user = username)\n",
        "        playlist = prep['items'][0]['id']\n",
        "        sp.user_playlist_add_tracks(user = username, playlist_id= playlist, tracks=songs_to_add)\n",
        "    else:\n",
        "        print(\"Can't get token for\", username)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pipeline\n",
        "def pipeline(input_words = [\"list\",\"of\",\"input\",\"words\"]):\n",
        "    # connect to database\n",
        "    conn = connect_db('data.db')\n",
        "    cur = conn.cursor()\n",
        "    input_words = input_words\n",
        "    pl_train = create_train(input_words, cur)\n",
        "    test_data, test_cols, data, data_cols, feature_cols= get_x_data(pl_train, cur)\n",
        "    conn.close()\n",
        "    data_df, scaled_x, scaled_y, scaled_features = scale_data(test_data, data, feature_cols)\n",
        "    #draw_scatterplot(data_df) \n",
        "    #calculate_num_clusters(scaled_x) # unfinished\n",
        "    n_clusters = 20 # manually set after looking at calculate_num_clusters\n",
        "    target_cluster = kmeans_init(data_df, scaled_x, scaled_y, n_clusters)\n",
        "\n",
        "    #draw_colored_scatterplot(data_df)\n",
        "    wordclouds = wordclouds(data_df, data, n_clusters)\n",
        "    tracks = get_target_cluster_songs(target_cluster[0], data_df, data)\n",
        "\n",
        "    # connect to spotify to create and add playlist\n",
        "    sp = connect_to_spotify()\n",
        "    playlist = generate_playlist(tracks)\n",
        "    create_playlist(sp, playlist, input_words)\n",
        "    return playlist, wordclouds"
        "    #wordclouds(data_df, data, n_clusters)\n",
        "    # tracks = get_target_cluster_songs(target_cluster, data_df, data)\n",
        "\n",
        "    #generate_playlist(tracks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "To create a public link, set `share=True` in `launch()`.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[12]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"c:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\routes.py\", line 292, in run_predict\n",
            "    output = await app.blocks.process_api(\n",
            "  File \"c:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\blocks.py\", line 1007, in process_api\n",
            "    result = await self.call_function(fn_index, inputs, iterator, request)\n",
            "  File \"c:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gradio\\blocks.py\", line 848, in call_function\n",
            "    prediction = await anyio.to_thread.run_sync(\n",
            "  File \"c:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\anyio\\to_thread.py\", line 31, in run_sync\n",
            "    return await get_asynclib().run_sync_in_worker_thread(\n",
            "  File \"c:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 937, in run_sync_in_worker_thread\n",
            "    return await future\n",
            "  File \"c:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\anyio\\_backends\\_asyncio.py\", line 867, in run\n",
            "    result = context.run(func, *args)\n",
            "  File \"C:\\Users\\alexp\\AppData\\Local\\Temp\\ipykernel_25360\\2864146359.py\", line 20, in pipeline\n",
            "    wordclouds = wordclouds(data_df, data, n_clusters)\n",
            "UnboundLocalError: local variable 'wordclouds' referenced before assignment\n"
          ]
        }
      ],
      "source": [
        "# def get_input_words(input_words, state):\n",
        "#     return input_words, input_words\n",
        "\n",
        "# get_input_words_interface = gr.Interface(fn=get_input_words, inputs=[\"text\",\"state\"], outputs=[\"state\"])\n",
        "# get_input_words_interface.launch() \n",
        "\n",
        "pipeline = gr.Interface(fn=pipeline, inputs=[\"text\"], outputs=[\"image\"])\n",
        "pipeline.launch()\n",
        "\n",
        "# def playlist_display(playlist):\n",
        "\n",
        "# playlist = gr.Interface(playlist_display, \"state\", \"spotify api connection\")    # how do this?"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.8 64-bit (microsoft store)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "e8398f7b216cace33c4ab6b86eb2f74027b6a3057174f31fee5a9109c187293f"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
