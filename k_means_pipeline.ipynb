{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2s023VS6NvV5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import spotipy\n",
        "import sqlite3\n",
        "from sklearn.cluster import KMeans\n",
        "from sqlite3 import Error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from openTSNE import TSNE as openTSNE\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS as STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "GWnx-v7ONvWA"
      },
      "outputs": [],
      "source": [
        "def connect_db(db_file):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "    except Error as e:\n",
        "        print(e)\n",
        "    return conn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "IwvA8npiNvWB"
      },
      "outputs": [],
      "source": [
        "# connect to database\n",
        "# conn = connect_db('data.db')\n",
        "# cur = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting the target data\n",
        "# Extract playlists that have the input words in their titles to use as training data\n",
        "# input_words = ['summer', 'beach', 'throwbacks']\n",
        "# sql_select = '''SELECT AVG(danceability), AVG(energy), AVG(key), AVG(loudness), \n",
        "# AVG(mode), AVG(speechiness), AVG(acousticness), AVG(instrumentalness), AVG(liveness), \n",
        "# AVG(valence), AVG(tempo), AVG(duration_ms), AVG(time_signature) FROM avg_features_by_playlist WHERE'''\n",
        "def create_train(input_words, cur):\n",
        "    sql_select = '''SELECT * FROM avg_features_by_playlist WHERE'''\n",
        "    for w in range(len(input_words)):\n",
        "        sql_select += \" name LIKE '%\" + input_words[w] + \"%'\"\n",
        "        if w != len(input_words) -1:\n",
        "            sql_select += \" OR\" \n",
        "    pl_train = cur.execute(sql_select).fetchall()\n",
        "    return pl_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PCfDJLzmNvWB",
        "outputId": "994a0280-a025-4982-83fd-bfe5a120c0c3"
      },
      "outputs": [],
      "source": [
        "def get_x_data(pl_train, cur):\n",
        "    # Get X data (average playlist features)\n",
        "    data_cols = ['pid', 'name', 'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "    feature_cols = ['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "    test_cols = ['pid', 'name', 'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "\n",
        "    data_rows = cur.execute('select * from avg_features_by_playlist where pid > (select MIN(pid) from avg_features_by_playlist) order by pid').fetchall()\n",
        "\n",
        "\n",
        "    # test_pl = cur.execute('''select tracks_in_playlist.pid, tracks_in_playlist.track_uri, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_ms, time_signature \n",
        "    # from features_by_track left join tracks_in_playlist on\n",
        "    # features_by_track.track_uri = tracks_in_playlist.track_uri \n",
        "    # where pid = (select MIN(pid) from avg_features_by_playlist)''').fetchall()\n",
        "\n",
        "\n",
        "    test_data = pd.DataFrame(pl_train, columns=test_cols)\n",
        "    data = pd.DataFrame(data_rows, columns=data_cols)\n",
        "\n",
        "    return test_data, test_cols, data, data_cols, feature_cols\n",
        "    # print(test_data.head())\n",
        "    # print(data.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "# conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ghXip9j4NvWD",
        "outputId": "b190b543-e694-46f0-a331-07272e7562a0"
      },
      "outputs": [],
      "source": [
        "# Scale the data\n",
        "\n",
        "def scale_data(test_data, data, feature_cols):\n",
        "    y = test_data[feature_cols].mean()\n",
        "\n",
        "    scaler = StandardScaler(with_mean=True, with_std=True).fit(data[feature_cols].values)\n",
        "\n",
        "    scaled_x = scaler.transform(data[feature_cols].values)\n",
        "    scaled_y = scaler.transform(np.array(y).reshape(1,-1))\n",
        "    scaled_features = pd.DataFrame(scaled_x)\n",
        "    tsne = openTSNE(perplexity=30, metric='euclidean', n_jobs=-1, random_state=0, verbose=False)\n",
        "    tsne_transformer = tsne.fit(scaled_x)\n",
        "    data_df = pd.DataFrame(tsne_transformer.transform(scaled_x), columns =['X', 'Y'])\n",
        "\n",
        "    #print(data_df, scaled_x, scaled_y, scaled_features)\n",
        "    return data_df, scaled_x, scaled_y, scaled_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qf9YiqzqNvWE",
        "outputId": "7cac83b7-e7e3-4125-a6ce-0f8ee47f6d64"
      },
      "outputs": [],
      "source": [
        "def draw_scatterplot(data_df):\n",
        "    sns.scatterplot(x='X', y='Y', data=data_df, legend=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MxtQj6Khbe4e"
      },
      "outputs": [],
      "source": [
        "def calculate_num_clusters(scaled_x):\n",
        "    #TODO:\n",
        "    # needs to be tested and K updated below\n",
        "    #calculate how many K clusters there should be \n",
        "    wcss = [] \n",
        "    for number_of_clusters in range(1, 30): \n",
        "        kmeans = KMeans(n_clusters = number_of_clusters, random_state = 42)\n",
        "        kmeans.fit(scaled_x) \n",
        "        wcss.append(kmeans.inertia_)\n",
        "    wcss\n",
        "\n",
        "    ks = range(1, 30)\n",
        "    plt.plot(ks, wcss)\n",
        "    plt.axvline(4, linestyle='--', color='r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "HboT_UKqNvWF"
      },
      "outputs": [],
      "source": [
        "def kmeans_init(data_df, scaled_x, scaled_y, n_clusters):\n",
        "    # initialize KMeans\n",
        "    \n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "    clusters = kmeans.fit(scaled_x)\n",
        "    labels = clusters.labels_\n",
        "    data_df['cluster'] = pd.Categorical(labels)\n",
        "\n",
        "    target_cluster = kmeans.predict(scaled_y)\n",
        "    print(target_cluster)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "czsdHYnjNvWG",
        "outputId": "437142d0-73d2-4d1b-925b-0643ca9bddaa"
      },
      "outputs": [],
      "source": [
        "def draw_colored_scatterplot(data_df):\n",
        "    sns.scatterplot(x='X', y='Y', hue='cluster', style='cluster', data=data_df, legend=None)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wordclouds(data_df, data, n_clusters):\n",
        "    data_df[\"playlist_name\"] = data['name'].str.lower()\n",
        "    # display(data_df)\n",
        "\n",
        "    # we want to perform a pivot on data_df so that each cluster number is a column with row value equal to the playlist name.\n",
        "    # from there we can sum up that column to get the whole lsit of strings of playlist names for each cluster (column)\n",
        "    original_df = data_df.pivot(index='X', columns='cluster')['playlist_name'].reset_index()\n",
        "    original_df.columns.name = None\n",
        "    original_df = original_df.fillna('')\n",
        "    # original_df.head(20)\n",
        "    # print(original_df.columns)\n",
        "\n",
        "    #list of words to ignore\n",
        "    stop_words = STOPWORDS.update([\"i\", \"it\", \"me\", \"my\", \"that\", \"the\", \"of\", \"than\", \"then\", \n",
        "    \"when\", \"if\", \"a\", \"there\", \"playlist\", \"music\", \"song\", \"songs\", \"to\", \"too\", \"get\", \"as\", \"this\", \n",
        "    \"am\", \"is\", \"are\", \"has\", \"and\", \"aa\", \"aaa\", 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', \n",
        "    'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
        "\n",
        "    wordclouds = {}\n",
        "    for i in range(n_clusters):\n",
        "        original_df.replace(np.nan, '')\n",
        "        original_df[i] = original_df[i].astype(str) #.sum(skipna=True))\n",
        "        wordclouds[\"wordcloud\" + str(i)] = WordCloud(stopwords=stop_words).generate(' '.join(original_df[i]))\n",
        "\n",
        "    for val in wordclouds.values():\n",
        "        plt.imshow(val)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_target_cluster_songs(target_cluster, data_df, data):\n",
        "    data_df[\"pid\"] = data['pid']\n",
        "    original_df = data_df.pivot(index='X', columns='cluster')['pid'].reset_index()\n",
        "    original_df.columns.name = None\n",
        "    target_cluster_df = original_df[target_cluster].dropna()\n",
        "    conn = connect_db('data.db')\n",
        "    cur = conn.cursor()\n",
        "    sql = '''SELECT features_by_track.* FROM features_by_track join tracks_in_playlist on features_by_track.track_uri = tracks_in_playlist.track_uri\n",
        "        WHERE '''\n",
        "    for pid in target_cluster_df[target_cluster[0]].values:\n",
        "        sql += \"tracks_in_playlist.pid = \" + str(int(pid))\n",
        "        sql += \" OR \"\n",
        "        sql = sql[:-3]\n",
        "        cols = [\"track_uri\",\n",
        "            \"danceability\",\n",
        "            \"energy\",\n",
        "            \"key\",\n",
        "            \"loudness\",\n",
        "            \"mode\",\n",
        "            \"speechiness\",\n",
        "            \"acousticness\",\n",
        "            \"instrumentalness\",\n",
        "            \"liveness\",\n",
        "            \"valence\",\n",
        "            \"tempo\",\n",
        "            \"duration_ms\",\n",
        "            \"time_signature\"]\n",
        "        \n",
        "    result = cur.execute(sql).fetchall()\n",
        "    \n",
        "    conn.close()\n",
        "    tracks = pd.DataFrame(result, columns = cols)\n",
        "    \n",
        "    print(tracks.head(5))\n",
        "    return tracks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "generate_playlist\n",
        "\n",
        "Parameters:\n",
        "input_words: (String) to pass to get_target_cluster_songs\n",
        "obscurity: (float) int\n",
        "max_song_length: (int) max_length of any song in the playlist\n",
        "use_minutes: (bool) use minutes instead of number of songs for playlist length (default false)\n",
        "playlist_length: number of songs in the playlist. If use_minutes=true, minutes in the playlist\n",
        "'''\n",
        "\n",
        "def generate_playlist(tracks, obscurity=1, max_song_length=10, use_minutes=False, playlist_length=10):\n",
        "    playlist = []\n",
        "    \n",
        "    \n",
        "    # obscurity\n",
        "    # length\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pipeline\n",
        "def pipeline():\n",
        "    # connect to database\n",
        "    conn = connect_db('data.db')\n",
        "    cur = conn.cursor()\n",
        "    input_words = [\"beach\",\"sun\"]\n",
        "    pl_train = create_train(input_words, cur)\n",
        "    test_data, test_cols, data, data_cols, feature_cols= get_x_data(pl_train, cur)\n",
        "    conn.close()\n",
        "    data_df, scaled_x, scaled_y, scaled_features = scale_data(test_data, data, feature_cols)\n",
        "    #draw_scatterplot(data_df) \n",
        "    #calculate_num_clusters(scaled_x) # unfinished\n",
        "    n_clusters = 20 # manually set after looking at calculate_num_clusters\n",
        "    target_cluster = kmeans_init(data_df, scaled_x, scaled_y, n_clusters)\n",
        "    #draw_colored_scatterplot(data_df)\n",
        "    #wordclouds(data_df, data, n_clusters)\n",
        "    tracks = get_target_cluster_songs(target_cluster, data_df, data)\n",
        "\n",
        "    #generate_playlist(tracks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1]\n"
          ]
        }
      ],
      "source": [
        "pipeline()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "771b2e09279bc50dd058e87d6b1c79418da63e1e1d4caf4728a325dde75439e2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
