{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "2s023VS6NvV5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import spotipy\n",
        "import sqlite3\n",
        "from sklearn.cluster import KMeans\n",
        "from sqlite3 import Error\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "import spotipy.util as util\n",
        "import time\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from openTSNE import TSNE as openTSNE\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS as STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "GWnx-v7ONvWA"
      },
      "outputs": [],
      "source": [
        "def connect_db(db_file):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "    except Error as e:\n",
        "        print(e)\n",
        "    return conn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "IwvA8npiNvWB"
      },
      "outputs": [],
      "source": [
        "# connect to database\n",
        "# conn = connect_db('data.db')\n",
        "# cur = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Getting the target data\n",
        "# Extract playlists that have the input words in their titles to use as training data\n",
        "# input_words = ['summer', 'beach', 'throwbacks']\n",
        "# sql_select = '''SELECT AVG(danceability), AVG(energy), AVG(key), AVG(loudness), \n",
        "# AVG(mode), AVG(speechiness), AVG(acousticness), AVG(instrumentalness), AVG(liveness), \n",
        "# AVG(valence), AVG(tempo), AVG(duration_ms), AVG(time_signature) FROM avg_features_by_playlist WHERE'''\n",
        "def create_train(input_words, cur):\n",
        "    sql_select = '''SELECT * FROM avg_features_by_playlist WHERE'''\n",
        "    for w in range(len(input_words)):\n",
        "        sql_select += \" name LIKE '%\" + input_words[w] + \"%'\"\n",
        "        if w != len(input_words) -1:\n",
        "            sql_select += \" OR\" \n",
        "    pl_train = cur.execute(sql_select).fetchall()\n",
        "    return pl_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "PCfDJLzmNvWB",
        "outputId": "994a0280-a025-4982-83fd-bfe5a120c0c3"
      },
      "outputs": [],
      "source": [
        "def get_x_data(pl_train, cur):\n",
        "    # Get X data (average playlist features)\n",
        "    data_cols = ['pid', 'name', 'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "    feature_cols = ['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "    test_cols = ['pid', 'name', 'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "\n",
        "    data_rows = cur.execute('select * from avg_features_by_playlist where pid > (select MIN(pid) from avg_features_by_playlist) order by pid').fetchall()\n",
        "\n",
        "\n",
        "    # test_pl = cur.execute('''select tracks_in_playlist.pid, tracks_in_playlist.track_uri, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_ms, time_signature \n",
        "    # from features_by_track left join tracks_in_playlist on\n",
        "    # features_by_track.track_uri = tracks_in_playlist.track_uri \n",
        "    # where pid = (select MIN(pid) from avg_features_by_playlist)''').fetchall()\n",
        "\n",
        "\n",
        "    test_data = pd.DataFrame(pl_train, columns=test_cols)\n",
        "    data = pd.DataFrame(data_rows, columns=data_cols)\n",
        "\n",
        "    return test_data, test_cols, data, data_cols, feature_cols\n",
        "    # print(test_data.head())\n",
        "    # print(data.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "# conn.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "ghXip9j4NvWD",
        "outputId": "b190b543-e694-46f0-a331-07272e7562a0"
      },
      "outputs": [],
      "source": [
        "# Scale the data\n",
        "\n",
        "def scale_data(test_data, data, feature_cols):\n",
        "    y = test_data[feature_cols].mean()\n",
        "\n",
        "    scaler = StandardScaler(with_mean=True, with_std=True).fit(data[feature_cols].values)\n",
        "\n",
        "    scaled_x = scaler.transform(data[feature_cols].values)\n",
        "    scaled_y = scaler.transform(np.array(y).reshape(1,-1))\n",
        "    scaled_features = pd.DataFrame(scaled_x)\n",
        "    tsne = openTSNE(perplexity=30, metric='euclidean', n_jobs=-1, random_state=0, verbose=False)\n",
        "    tsne_transformer = tsne.fit(scaled_x)\n",
        "    data_df = pd.DataFrame(tsne_transformer.transform(scaled_x), columns =['X', 'Y'])\n",
        "\n",
        "    #print(data_df, scaled_x, scaled_y, scaled_features)\n",
        "    return data_df, scaled_x, scaled_y, scaled_features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "qf9YiqzqNvWE",
        "outputId": "7cac83b7-e7e3-4125-a6ce-0f8ee47f6d64"
      },
      "outputs": [],
      "source": [
        "def draw_scatterplot(data_df):\n",
        "    sns.scatterplot(x='X', y='Y', data=data_df, legend=None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "MxtQj6Khbe4e"
      },
      "outputs": [],
      "source": [
        "def calculate_num_clusters(scaled_x):\n",
        "    #TODO:\n",
        "    # needs to be tested and K updated below\n",
        "    #calculate how many K clusters there should be \n",
        "    wcss = [] \n",
        "    for number_of_clusters in range(1, 30): \n",
        "        kmeans = KMeans(n_clusters = number_of_clusters, random_state = 42)\n",
        "        kmeans.fit(scaled_x) \n",
        "        wcss.append(kmeans.inertia_)\n",
        "    wcss\n",
        "\n",
        "    ks = range(1, 30)\n",
        "    plt.plot(ks, wcss)\n",
        "    plt.axvline(4, linestyle='--', color='r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "HboT_UKqNvWF"
      },
      "outputs": [],
      "source": [
        "def kmeans_init(data_df, scaled_x, scaled_y, n_clusters):\n",
        "    # initialize KMeans\n",
        "    \n",
        "    kmeans = KMeans(n_clusters=n_clusters, random_state=0)\n",
        "    clusters = kmeans.fit(scaled_x)\n",
        "    labels = clusters.labels_\n",
        "    # return cluster centers. from there, use euclidean distance\n",
        "    #clusters.cluster_centers\n",
        "    data_df['cluster'] = pd.Categorical(labels)\n",
        "\n",
        "    target_cluster = kmeans.predict(scaled_y)\n",
        "    print(target_cluster)\n",
        "    return target_cluster"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "czsdHYnjNvWG",
        "outputId": "437142d0-73d2-4d1b-925b-0643ca9bddaa"
      },
      "outputs": [],
      "source": [
        "def draw_colored_scatterplot(data_df):\n",
        "    sns.scatterplot(x='X', y='Y', hue='cluster', style='cluster', data=data_df, legend=None)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [],
      "source": [
        "def wordclouds(data_df, data, n_clusters):\n",
        "    data_df[\"playlist_name\"] = data['name'].str.lower()\n",
        "    # display(data_df)\n",
        "\n",
        "    # we want to perform a pivot on data_df so that each cluster number is a column with row value equal to the playlist name.\n",
        "    # from there we can sum up that column to get the whole lsit of strings of playlist names for each cluster (column)\n",
        "    original_df = data_df.pivot(index='X', columns='cluster')['playlist_name'].reset_index()\n",
        "    original_df.columns.name = None\n",
        "    original_df = original_df.fillna('')\n",
        "    # original_df.head(20)\n",
        "    # print(original_df.columns)\n",
        "\n",
        "    #list of words to ignore\n",
        "    stop_words = STOPWORDS.update([\"i\", \"it\", \"me\", \"my\", \"that\", \"the\", \"of\", \"than\", \"then\", \n",
        "    \"when\", \"if\", \"a\", \"there\", \"playlist\", \"music\", \"song\", \"songs\", \"to\", \"too\", \"get\", \"as\", \"this\", \n",
        "    \"am\", \"is\", \"are\", \"has\", \"and\", \"aa\", \"aaa\", 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'j', 'k', 'l', 'm', 'n', \n",
        "    'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z'])\n",
        "\n",
        "    wordclouds = {}\n",
        "    for i in range(n_clusters):\n",
        "        original_df.replace(np.nan, '')\n",
        "        original_df[i] = original_df[i].astype(str) #.sum(skipna=True))\n",
        "        wordclouds[\"wordcloud\" + str(i)] = WordCloud(stopwords=stop_words).generate(' '.join(original_df[i]))\n",
        "\n",
        "    for val in wordclouds.values():\n",
        "        plt.imshow(val)\n",
        "        plt.axis(\"off\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_target_cluster_songs(target_cluster, data_df, data):\n",
        "    data_df[\"pid\"] = data['pid']\n",
        "    original_df = data_df.pivot(columns='cluster', values='pid')\n",
        "    target_cluster_df = original_df[[target_cluster]].dropna()\n",
        "    conn = connect_db('data.db')\n",
        "    cur = conn.cursor()\n",
        "    sql = '''SELECT features_by_track.* FROM features_by_track join tracks_in_playlist on features_by_track.track_uri = tracks_in_playlist.track_uri\n",
        "        WHERE '''\n",
        "    for pid in target_cluster_df[target_cluster].values:\n",
        "        sql += \"tracks_in_playlist.pid = \" + str(int(pid))\n",
        "        sql += \" OR \"\n",
        "    sql = sql[:-3]\n",
        "    cols = [\"track_uri\",\n",
        "        \"danceability\",\n",
        "        \"energy\",\n",
        "        \"key\",\n",
        "        \"loudness\",\n",
        "        \"mode\",\n",
        "        \"speechiness\",\n",
        "        \"acousticness\",\n",
        "        \"instrumentalness\",\n",
        "        \"liveness\",\n",
        "        \"valence\",\n",
        "        \"tempo\",\n",
        "        \"duration_ms\",\n",
        "        \"time_signature\"]\n",
        "        \n",
        "    result = cur.execute(sql).fetchall()\n",
        "    \n",
        "    conn.close()\n",
        "    tracks = pd.DataFrame(result, columns = cols)\n",
        "    tracks = tracks[tracks['track_uri'].map(tracks['track_uri'].value_counts()) > 3]\n",
        "    \n",
        "    tracks['counts'] = tracks.groupby(['track_uri'])['time_signature'].transform('count')\n",
        "    \n",
        "    tracks = tracks.drop_duplicates(subset=['track_uri'])\n",
        "    song_instances = tracks['counts'].sum()\n",
        "\n",
        "    \n",
        "    #num_unique_songs = len(pd.unique(tracks['track_uri']))\n",
        "    print(song_instances, \" song instances fetched\")\n",
        "    print(len(tracks), \" unique songs fetched\")\n",
        "    print(tracks.head(5))\n",
        "    return tracks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {},
      "outputs": [],
      "source": [
        "'''\n",
        "generate_playlist\n",
        "\n",
        "Parameters:\n",
        "input_words: (String) to pass to get_target_cluster_songs\n",
        "obscurity: (float) int\n",
        "max_song_length: (int) max_length of any song in the playlist\n",
        "#use_minutes: (bool) use minutes instead of number of songs for playlist length (default false)\n",
        "playlist_length: number of songs in the playlist. #If use_minutes=true, minutes in the playlist\n",
        "'''\n",
        "\n",
        "def generate_playlist(tracks, obscurity=1, max_song_length=10, use_minutes=False, playlist_length=10):\n",
        "    playlist = []\n",
        "    for track in tracks:\n",
        "        playlist.append(track)\n",
        "        #print(track)\n",
        "    #print(playlist)\n",
        "    \n",
        "    # obscurity\n",
        "    # length\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def connect_to_spotify():\n",
        "    # Spotify credentials\n",
        "    cid = \"5cffc2676cd44b35bc6af81faeb8e69a\"\n",
        "    secret = \"f9fdae88362349b992ab2714ea91a094\"\n",
        "    os.environ[\"SPOTIPY_CLIENT_ID\"] = cid\n",
        "    os.environ[\"SPOTIPY_CLIENT_SECRET\"] = secret\n",
        "    os.environ['SPOTIPY_REDIRECT_URI'] = \"http://127.0.0.1:8080\"\n",
        "    client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
        "    sp = spotipy.Spotify(client_credentials_manager = SpotifyClientCredentials())\n",
        "\n",
        "    return sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_playlist(sp, songs):\n",
        "    #must give a list of track ids, must include \"spotify:track:\"\n",
        "    user_id = \"1a0f1b9085db4f49\"\n",
        "    username = \"31y7j5k3jeidd5rzhaznsdregg34\"\n",
        "    playlistName = \"\"\n",
        "    scope = \"playlist-modify-public\"\n",
        "    songs_to_add = []\n",
        "    c = 0\n",
        "    for i in input_words:\n",
        "        playlistName += input_words[c] + \" \"\n",
        "        c += 1\n",
        "        \n",
        "    c = 0\n",
        "    for i in songs_to_add:\n",
        "        songs_to_add[c] = \"spotify:track:\" + songs['track_uri']\n",
        "        c += 1\n",
        "\n",
        "    token = SpotifyOAuth(scope = scope, username = username)\n",
        "    if token:\n",
        "        sp = spotipy.Spotify(auth_manager=token)\n",
        "        sp.user_playlist_create(user = username, name = playlistName)\n",
        "        prep = sp.user_playlists(user = username)\n",
        "        playlist = prep['items'][0]['id']\n",
        "        sp.user_playlist_add_tracks(user = username, playlist_id= playlist, tracks=songs_to_add)\n",
        "    else:\n",
        "        print(\"Can't get token for\", username)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pipeline\n",
        "def pipeline():\n",
        "    # connect to database\n",
        "    conn = connect_db('data.db')\n",
        "    cur = conn.cursor()\n",
        "    input_words = [\"beach\",\"sun\"]\n",
        "    pl_train = create_train(input_words, cur)\n",
        "\n",
        "    test_data, test_cols, data, data_cols, feature_cols= get_x_data(pl_train, cur)\n",
        "    conn.close()\n",
        "    data_df, scaled_x, scaled_y, scaled_features = scale_data(test_data, data, feature_cols)\n",
        "\n",
        "    data_df = pd.read_csv(\"cluster.csv\")\n",
        "    #draw_scatterplot(data_df) \n",
        "    #calculate_num_clusters(scaled_x) # unfinished\n",
        "    n_clusters = 20 # manually set after looking at calculate_num_clusters\n",
        "    target_cluster = kmeans_init(data_df, scaled_x, scaled_y, n_clusters)\n",
        "\n",
        "    #draw_colored_scatterplot(data_df)\n",
        "    #wordclouds(data_df, data, n_clusters)\n",
        "    tracks = get_target_cluster_songs(target_cluster[0], data_df, data)\n",
        "\n",
        "    # connect to spotify to create and add playlist\n",
        "    sp = connect_to_spotify()\n",
        "    playlist = generate_playlist(tracks)\n",
        "    create_playlist(sp, playlist)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "Length of values (999) does not match length of index (999999)",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\alexp\\Documents\\GitHub\\cs254_playlist_project\\k_means_pipeline.ipynb Cell 16\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m pipeline()\n",
            "\u001b[1;32mc:\\Users\\alexp\\Documents\\GitHub\\cs254_playlist_project\\k_means_pipeline.ipynb Cell 16\u001b[0m in \u001b[0;36mpipeline\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39m#draw_scatterplot(data_df) \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39m#calculate_num_clusters(scaled_x) # unfinished\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m n_clusters \u001b[39m=\u001b[39m \u001b[39m20\u001b[39m \u001b[39m# manually set after looking at calculate_num_clusters\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m target_cluster \u001b[39m=\u001b[39m kmeans_init(data_df, scaled_x, scaled_y, n_clusters)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m#draw_colored_scatterplot(data_df)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#wordclouds(data_df, data, n_clusters)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m tracks \u001b[39m=\u001b[39m get_target_cluster_songs(target_cluster[\u001b[39m0\u001b[39m], data_df, data)\n",
            "\u001b[1;32mc:\\Users\\alexp\\Documents\\GitHub\\cs254_playlist_project\\k_means_pipeline.ipynb Cell 16\u001b[0m in \u001b[0;36mkmeans_init\u001b[1;34m(data_df, scaled_x, scaled_y, n_clusters)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m clusters \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mfit(scaled_x)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m labels \u001b[39m=\u001b[39m clusters\u001b[39m.\u001b[39mlabels_\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m data_df[\u001b[39m'\u001b[39m\u001b[39mcluster\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mCategorical(labels)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m target_cluster \u001b[39m=\u001b[39m kmeans\u001b[39m.\u001b[39mpredict(scaled_y)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/alexp/Documents/GitHub/cs254_playlist_project/k_means_pipeline.ipynb#X21sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(target_cluster)\n",
            "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3655\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3652\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3653\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3654\u001b[0m     \u001b[39m# set column\u001b[39;00m\n\u001b[1;32m-> 3655\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_set_item(key, value)\n",
            "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:3832\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3822\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_set_item\u001b[39m(\u001b[39mself\u001b[39m, key, value) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   3823\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3824\u001b[0m \u001b[39m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   3825\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3830\u001b[0m \u001b[39m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   3831\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3832\u001b[0m     value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sanitize_column(value)\n\u001b[0;32m   3834\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   3835\u001b[0m         key \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\n\u001b[0;32m   3836\u001b[0m         \u001b[39mand\u001b[39;00m value\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   3837\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m is_extension_array_dtype(value)\n\u001b[0;32m   3838\u001b[0m     ):\n\u001b[0;32m   3839\u001b[0m         \u001b[39m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   3840\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mis_unique \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns, MultiIndex):\n",
            "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\frame.py:4529\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   4526\u001b[0m     \u001b[39mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex)\n\u001b[0;32m   4528\u001b[0m \u001b[39mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 4529\u001b[0m     com\u001b[39m.\u001b[39;49mrequire_length_match(value, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindex)\n\u001b[0;32m   4530\u001b[0m \u001b[39mreturn\u001b[39;00m sanitize_array(value, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, copy\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, allow_2d\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
            "File \u001b[1;32mc:\\Users\\alexp\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pandas\\core\\common.py:557\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    554\u001b[0m \u001b[39mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    555\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    556\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m!=\u001b[39m \u001b[39mlen\u001b[39m(index):\n\u001b[1;32m--> 557\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    558\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mLength of values \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    559\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(data)\u001b[39m}\u001b[39;00m\u001b[39m) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    560\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdoes not match length of index \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    561\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m(\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mlen\u001b[39m(index)\u001b[39m}\u001b[39;00m\u001b[39m)\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    562\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: Length of values (999) does not match length of index (999999)"
          ]
        }
      ],
      "source": [
        "pipeline()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "771b2e09279bc50dd058e87d6b1c79418da63e1e1d4caf4728a325dde75439e2"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
