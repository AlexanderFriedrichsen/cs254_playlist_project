{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This file shows all the ways that our cluster numbers were analysed "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import spotipy\n",
        "import sqlite3\n",
        "from sklearn.cluster import KMeans\n",
        "from sqlite3 import Error\n",
        "import matplotlib.pyplot as plt\n",
        "from spotipy.oauth2 import SpotifyClientCredentials\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.manifold import TSNE\n",
        "from openTSNE import TSNE as openTSNE\n",
        "from sklearn.metrics import silhouette_score, silhouette_samples\n",
        "from wordcloud import WordCloud\n",
        "from wordcloud import STOPWORDS as STOPWORDS\n",
        "from sklearn.decomposition import PCA\n",
        "from yellowbrick.cluster import SilhouetteVisualizer\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_tables(conn):\n",
        "    try:\n",
        "        cur = conn.cursor()\n",
        "        # create playlist table\n",
        "        cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS playlists (\n",
        "                                    name text NOT NULL,\n",
        "                                    collaborative text,\n",
        "                                    pid integer NOT NULL primary key,\n",
        "                                    modified_at integer,\n",
        "                                    num_tracks integer,\n",
        "                                    num_albums integer,\n",
        "                                    num_followers integer,\n",
        "                                    num_edits integer,\n",
        "                                    duration_ms integer,\n",
        "                                    num_artists integer\n",
        "                                );\"\"\")\n",
        "                                \n",
        "        # create tracks table\n",
        "        cur.execute(\"\"\" CREATE TABLE IF NOT EXISTS tracks (\n",
        "                                    artist_name text,\n",
        "                                    track_uri text NOT NULL primary key,\n",
        "                                    artist_uri text,\n",
        "                                    track_name text NOT NULL,\n",
        "                                    album_uri text,\n",
        "                                    album_name text,\n",
        "                                    track_id integer,\n",
        "                                    pid integer\n",
        "                                    ); \"\"\")\n",
        "        cur.execute(\"\"\"CREATE TABLE IF NOT EXISTS tracks_in_playlist (\n",
        "                                    pid integer NOT NULL,\n",
        "                                    track_uri\n",
        "        );\"\"\")\n",
        "        # create features table\n",
        "        cur.execute(\"\"\" CREATE TABLE IF NOT EXISTS features_by_track (\n",
        "                                    track_uri text primary key,\n",
        "                                    danceability real,\n",
        "                                    energy real,\n",
        "                                    key real,\n",
        "                                    loudness real,\n",
        "                                    mode real,\n",
        "                                    speechiness real,\n",
        "                                    acousticness real,\n",
        "                                    instrumentalness real,\n",
        "                                    liveness real,\n",
        "                                    valence real,\n",
        "                                    tempo real,\n",
        "                                    duration_ms integer,\n",
        "                                    time_signature integer\n",
        "                                    ); \"\"\")\n",
        "        \n",
        "        cur.execute(\"\"\" CREATE TABLE IF NOT EXISTS avg_features_by_playlist (\n",
        "                                    pid integer NOT NULL primary key,\n",
        "                                    name NOT NULL,\n",
        "                                    danceability real,\n",
        "                                    energy real,\n",
        "                                    key real,\n",
        "                                    loudness real,\n",
        "                                    mode real,\n",
        "                                    speechiness real,\n",
        "                                    acousticness real,\n",
        "                                    instrumentalness real,\n",
        "                                    liveness real,\n",
        "                                    valence real,\n",
        "                                    tempo real,\n",
        "                                    duration_ms integer,\n",
        "                                    time_signature integer\n",
        "        );\"\"\")\n",
        "\n",
        "    except Error as e: \n",
        "        print(e)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_json_data(json_data, num_playlists, conn):\n",
        "  # Get all playlists in the file\n",
        "  playlists_df = pd.json_normalize(json_data['playlists'])\n",
        "  playlists_df.drop(['tracks', 'description'], axis=1, inplace=True)\n",
        "  playlists_df['name'].str.lower()\n",
        "  playlists_df.to_sql(name='playlists', con=conn, if_exists='append', index=False)\n",
        "  # Get all the tracks in the file\n",
        "  cur = conn.cursor()\n",
        "  cur.execute(\"select max(track_id) from tracks\")\n",
        "  rows = cur.fetchall()\n",
        "  max_track_id = rows[0][0]\n",
        "  if max_track_id is None:\n",
        "      max_track_id = 0\n",
        "  tracks_df = pd.json_normalize(json_data['playlists'], record_path=['tracks'], meta=['pid', 'num_followers'])\n",
        "  #tracks_in_playlist_df.to_sql(name=\"tracks_in_playlist\", con=conn, if_exists='append', index=False)\n",
        "  tracks_df = tracks_df[tracks_df['pid'].isin(playlists_df['pid'].values)]\n",
        "  tracks_df['track_uri'] = tracks_df['track_uri'].apply(lambda uri: uri.split(':')[2])\n",
        "  tracks_df['album_uri'] = tracks_df['album_uri'].apply(lambda uri: uri.split(':')[2])\n",
        "  tracks_df['artist_uri'] = tracks_df['artist_uri'].apply(lambda uri: uri.split(':')[2])\n",
        "\n",
        "  tracks_in_playlist_df = tracks_df[['pid', 'track_uri']]\n",
        "  tracks_in_playlist_df.to_sql(name='tracks_in_playlist', con=conn, if_exists='append', index=False)\n",
        "\n",
        "  all_tracks_df = pd.read_sql('select track_id, track_uri from tracks', conn)\n",
        "  tracks_df = tracks_df.merge(all_tracks_df, how='left', on='track_uri').fillna(0)\n",
        "  tracks_df['track_id1'] = tracks_df[tracks_df[\"track_id\"] == 0][['track_uri']].groupby('track_uri').ngroup()+max_track_id+1\n",
        "  tracks_df['track_id'] = tracks_df['track_id'] + tracks_df['track_id1'].fillna(0)\n",
        "  tracks_df['track_id'] = tracks_df['track_id'].astype('int64')\n",
        "  tracks_df = tracks_df[tracks_df['track_id1'].notna()]\n",
        "  tracks_df.drop(['pos', 'duration_ms', 'pid', 'num_followers', 'track_id1'], axis=1, inplace=True)\n",
        "  tracks_df = tracks_df.drop_duplicates(subset='track_uri', keep=\"first\")\n",
        "  tracks_df.to_sql(name='tracks', con=conn, if_exists='append', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_playlists(path, num_files, num_playlists, conn):\n",
        "    cur = conn.cursor()\n",
        "\n",
        "    # Don't process playlists that have already been processed\n",
        "    # This allows for us to add more playlist and song data to the db as we go along with dev\n",
        "    cur.execute('select count(pid) from playlists')\n",
        "    count = cur.fetchall()[0][0] / 1000\n",
        "    if count == num_files:\n",
        "        return\n",
        "    playlists = []\n",
        "    filenames = os.listdir(path)\n",
        "    for fname in sorted(filenames):\n",
        "        if fname.startswith(\"mpd.slice.\") and fname.endswith(\".json\"):\n",
        "            count += 1\n",
        "            full_path = os.sep.join((path, fname))\n",
        "            with open(full_path) as f:\n",
        "                js = json.loads(f.read())\n",
        "                print(\"Processing playlist file\", count)\n",
        "                process_json_data(js, num_playlists, conn)\n",
        "            if count == num_files and num_files > 0:\n",
        "                break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def connect_db(db_file):\n",
        "    conn = None\n",
        "    try:\n",
        "        conn = sqlite3.connect(db_file)\n",
        "    except Error as e:\n",
        "        print(e)\n",
        "    return conn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# connect to database\n",
        "conn = connect_db('data.db')\n",
        "cur = conn.cursor()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "process_playlists(path, 1, 0, conn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def connect_to_spotify():\n",
        "    # Spotify credentials\n",
        "    cid = \"5cffc2676cd44b35bc6af81faeb8e69a\"\n",
        "    secret = \"f9fdae88362349b992ab2714ea91a094\"\n",
        "    os.environ[\"SPOTIPY_CLIENT_ID\"] = cid\n",
        "    os.environ[\"SPOTIPY_CLIENT_SECRET\"] = secret\n",
        "    os.environ['SPOTIPY_REDIRECT_URI'] = \"http://localhost:8080\"\n",
        "    client_credentials_manager = SpotifyClientCredentials(client_id=cid, client_secret=secret)\n",
        "    sp = spotipy.Spotify(client_credentials_manager = SpotifyClientCredentials())\n",
        "\n",
        "    return sp"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_spotify_features():\n",
        "    sp = connect_to_spotify()\n",
        "    cur = conn.cursor()\n",
        "    # Don't load features for songs that are already loaded\n",
        "    cur.execute('''select tracks.track_id, tracks.track_uri, tracks.artist_name from tracks \n",
        "    where tracks.track_uri not in (select features_by_track.track_uri from features_by_track)''')\n",
        "    rows = cur.fetchall()\n",
        "    num_tracks = len(rows)\n",
        "    if num_tracks != 0:\n",
        "        print(num_tracks, \" songs do not have features loaded yet.\")\n",
        "        uris = [row[1] for row in rows]\n",
        "        artists = [row[2] for row in rows]\n",
        "        feats_list = []\n",
        "        for i in range(0, len(uris), 100):\n",
        "            feats_list += sp.audio_features(uris[i:(i+100)])\n",
        "        # Remove None items, for some tracks there are no features\n",
        "        feats_list = [item for item in feats_list if item]\n",
        "        features_df = pd.DataFrame(feats_list)\n",
        "        features = ['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "        features_df = features_df[features]\n",
        "        features_df.insert(loc=0, column='track_uri', value=uris)\n",
        "        features_df.to_sql(name='features_by_track', con=conn, if_exists='append', index=False)\n",
        "\n",
        "    # get the average features for each playlist and put into another table, along with the playlist name\n",
        "    # cur.execute('select tracks_in_playlist.pid, playlists.name, features_by_track.* from features_by_track join tracks_in_playlist on tracks_in_playlist.track_uri = features_by_track.track_uri join playlists on tracks_in_playlist.pid = playlists.pid')\n",
        "    # rows = cur.fetchall()\n",
        "    \n",
        "        cur.execute('''insert into avg_features_by_playlist select tracks_in_playlist.pid, playlists.name, AVG(features_by_track.danceability), AVG(features_by_track.energy), \n",
        "                    AVG('features_by_track.key'), AVG(features_by_track.loudness), AVG('features_by_track.mode'), AVG(features_by_track.speechiness),\n",
        "                        AVG(features_by_track.acousticness), AVG(features_by_track.instrumentalness), AVG(features_by_track.liveness), AVG(features_by_track.valence), \n",
        "                        AVG(features_by_track.tempo), AVG(features_by_track.duration_ms), AVG(features_by_track.time_signature)\n",
        "                        from features_by_track join tracks_in_playlist on tracks_in_playlist.track_uri = features_by_track.track_uri join playlists on tracks_in_playlist.pid = playlists.pid group by tracks_in_playlist.pid''')\n",
        "    elif not cur.execute('select count(pid) from avg_features_by_playlist group by pid').fetchall():\n",
        "        cur.execute('''insert into avg_features_by_playlist select tracks_in_playlist.pid, playlists.name, AVG(features_by_track.danceability), AVG(features_by_track.energy), \n",
        "                    AVG('features_by_track.key'), AVG(features_by_track.loudness), AVG('features_by_track.mode'), AVG(features_by_track.speechiness),\n",
        "                        AVG(features_by_track.acousticness), AVG(features_by_track.instrumentalness), AVG(features_by_track.liveness), AVG(features_by_track.valence), \n",
        "                        AVG(features_by_track.tempo), AVG(features_by_track.duration_ms), AVG(features_by_track.time_signature)\n",
        "                        from features_by_track join tracks_in_playlist on tracks_in_playlist.track_uri = features_by_track.track_uri join playlists on tracks_in_playlist.pid = playlists.pid group by tracks_in_playlist.pid''')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "get_spotify_features()\n",
        "conn.commit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Testing to verify that all data was correctly processed\n",
        "\n",
        "cur = conn.cursor()\n",
        "cur.execute('select count(pid) from avg_features_by_playlist')\n",
        "num_pl_avg_f = cur.fetchall()[0][0]\n",
        "\n",
        "cur.execute('select count(pid) from playlists')\n",
        "num_pl = cur.fetchall()[0][0]\n",
        "\n",
        "cur.execute('select count(pid) from tracks_in_playlist group by pid')\n",
        "num_pl_tip = len(cur.fetchall())\n",
        "print(num_pl_tip)\n",
        "\n",
        "cur.execute('select count(track_uri) from features_by_track')\n",
        "num_trks_fbt = cur.fetchall()[0][0]\n",
        "\n",
        "cur.execute('select count(track_uri) from tracks')\n",
        "num_trks = cur.fetchall()[0][0]\n",
        "\n",
        "if(num_pl == num_pl_avg_f and num_pl_avg_f == num_pl_tip and num_pl > 0):\n",
        "    print(\"All playlists were successfully processed\")\n",
        "else:\n",
        "    print(\"Error: not all playlists were processed\")\n",
        "\n",
        "if(num_trks == num_trks_fbt):\n",
        "    print(\"All songs in the playlists and their features were processed\")\n",
        "else:\n",
        "    print(\"Error: not all songs or not all features were processed\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get X data (average playlist features)\n",
        "data_cols = ['pid', 'name', 'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "feature_cols = ['danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "test_cols = ['pid', 'track_uri', 'danceability','energy','key','loudness','mode','speechiness','acousticness','instrumentalness','liveness','valence','tempo','duration_ms','time_signature']\n",
        "\n",
        "data_rows = cur.execute('select * from avg_features_by_playlist where pid > (select MIN(pid) from avg_features_by_playlist) order by pid').fetchall()\n",
        "\n",
        "\n",
        "test_pl = cur.execute('''select tracks_in_playlist.pid, tracks_in_playlist.track_uri, danceability, energy, key, loudness, mode, speechiness, acousticness, instrumentalness, liveness, valence, tempo, duration_ms, time_signature \n",
        "from features_by_track left join tracks_in_playlist on\n",
        "features_by_track.track_uri = tracks_in_playlist.track_uri \n",
        "where pid = (select MIN(pid) from avg_features_by_playlist)''').fetchall()\n",
        "\n",
        "test_data = pd.DataFrame(test_pl, columns=test_cols)\n",
        "data = pd.DataFrame(data_rows, columns=data_cols)\n",
        "\n",
        "print(test_data.head())\n",
        "print(data.head(5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Scale the data\n",
        "\n",
        "\n",
        "y = test_data[feature_cols].mean()\n",
        "\n",
        "scaler = StandardScaler(with_mean=True, with_std=True).fit(data[feature_cols].values)\n",
        "\n",
        "scaled_x = scaler.transform(data[feature_cols].values)\n",
        "scaled_y = scaler.transform(np.array(y).reshape(1,-1))\n",
        "scaled_features = pd.DataFrame(scaled_x)\n",
        "tsne = openTSNE(perplexity=30, metric='euclidean', n_jobs=-1, random_state=0, verbose=False)\n",
        "tsne_transformer = tsne.fit(scaled_x)\n",
        "data_df = pd.DataFrame(tsne_transformer.transform(scaled_x), columns =['X', 'Y'])\n",
        "\n",
        "print(data_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jvo9O8RqJ0fZ"
      },
      "outputs": [],
      "source": [
        "#calculate how many K clusters there should be \n",
        "wcss = [] \n",
        "for number_of_clusters in range(1, 30): \n",
        "    kmeans = KMeans(n_clusters = number_of_clusters, random_state = 42)\n",
        "    kmeans.fit(scaled_x) \n",
        "    wcss.append(kmeans.inertia_)\n",
        "wcss\n",
        "\n",
        "ks = range(1, 30)\n",
        "plt.plot(ks, wcss)\n",
        "plt.axvline(18, linestyle='--', color='r')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pca_num_components = 2\n",
        "reduced = PCA(n_components=pca_num_components, svd_solver='full')\n",
        "reduced.fit_transform(scaled_x)\n",
        "print(reduced.explained_variance_ratio_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ePwV_xVZJ8ns"
      },
      "outputs": [],
      "source": [
        "# initialize KMeans\n",
        "kmeans = KMeans(n_clusters=18, random_state=0)\n",
        "clusters = kmeans.fit(reduced)\n",
        "labels = clusters.labels_\n",
        "data_df['cluster'] = pd.Categorical(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_oqeyBuJ-S_"
      },
      "outputs": [],
      "source": [
        "score = silhouette_score(reduced, clusters.labels_, metric='euclidean')\n",
        "print('Silhouetter Score: %.3f' % score)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQ_kVRF9KA4H"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "from yellowbrick.cluster import KElbowVisualizer\n",
        "\n",
        "visualizer = KElbowVisualizer(kmeans, k=(2,24))\n",
        " \n",
        "visualizer.fit(reduced)        # Fit the data to the visualizer\n",
        "visualizer.show() \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QRyHXuTZKDA1"
      },
      "outputs": [],
      "source": [
        "range_n_clusters = [16, 18, 20, 22, 24, 26, 28, 30]\n",
        "silhouette_avg = []\n",
        "for num_clusters in range_n_clusters:  \n",
        "  # initialise kmeans\n",
        "  kmeans = KMeans(n_clusters=num_clusters)\n",
        "  kmeans.fit(scaled_x)\n",
        "  cluster_labels = kmeans.labels_\n",
        " \n",
        "  # silhouette score\n",
        "  silhouette_avg.append(silhouette_score(reduced, cluster_labels))\n",
        "plt.plot(range_n_clusters,silhouette_avg)\n",
        "plt.xlabel(\"Values of K\") \n",
        "plt.ylabel(\"Silhouette score\") \n",
        "plt.title(\"Silhouette analysis For Optimal k\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nyN8kOxiKFCY"
      },
      "outputs": [],
      "source": [
        "visualizer = KElbowVisualizer(kmeans, k=(17, 24))\n",
        " \n",
        "visualizer.fit(scaled_x)        # Fit the data to the visualizer\n",
        "visualizer.show() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bmUrGGoWKG6p"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(2, 2, figsize=(15,8))\n",
        "for i in [2, 3, 4, 5]:\n",
        "    '''\n",
        "    Create KMeans instance for different number of clusters\n",
        "    '''\n",
        "    km = KMeans(n_clusters=i, init='k-means++', n_init=10, max_iter=100, random_state=42)\n",
        "    q, mod = divmod(i, 2)\n",
        "    '''\n",
        "    Create SilhouetteVisualizer instance with KMeans instance\n",
        "    Fit the visualizer\n",
        "    '''\n",
        "    visualizer = SilhouetteVisualizer(km, colors='yellowbrick', ax=ax[q-1][mod])\n",
        "    visualizer.fit(scaled_x)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
